{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOQG/OLqsaQguJZhdWUGll2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["3 To - Do Exercise:\n","\n","For the provided dataset:\n","\n","• diabetes.csv\n","\n","\n","Complete the following Problems."],"metadata":{"id":"k-Dj6xZXsTf0"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"NdUBRK1YwF2a"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKnrivg1sOm0"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv('/content/drive/MyDrive/diabetes.csv')"]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"6C1vgfZuw5oT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Problem - 1: Perform a classification task with knn from scratch.\n","1. Load the Dataset:\n","\n","• Read the dataset into a pandas DataFrame.\n","\n","• Display the first few rows and perform exploratory data analysis (EDA) to understand the dataset\n","(e.g., check data types, missing values, summary statistics).\n","\n","2. Handle Missing Data:\n","\n","• Handle any missing values appropriately, either by dropping or imputing them based on the data.\n","\n","3. Feature Engineering:\n","\n","• Separate the feature matrix (X) and target variable (y).\n","\n","• Perform a train - test split from scratch using a 70% − 30% ratio.\n","\n","4. Implement KNN:\n","\n","• Build the KNN algorithm from scratch (no libraries like sickit-learn for KNN).\n","\n","• Compute distances using Euclidean distance.\n","\n","• Write functions for:\n","\n","– Predicting the class for a single query.\n","\n","– Predicting classes for all test samples.\n","\n","• Evaluate the performance using accuracy."],"metadata":{"id":"RvIGiPeLxSVE"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from collections import Counter\n","\n","# 1. Load the Dataset\n","file_path = \"/content/drive/MyDrive/diabetes.csv\"  # Ensure this file path is valid\n","df = load_and_explore_dataset('/content/drive/MyDrive/diabetes.csv')\n","    # Read the dataset\n","df = pd.read_csv(\"/content/drive/MyDrive/diabetes.csv\")\n","\n","# Display the first few rows and perform EDA\n","print(\"First few rows:\")\n","print(df.head())\n","\n","print(\"\\nData Types:\")\n","print(df.dtypes)\n","\n","print(\"\\nMissing Values:\")\n","print(df.isnull().sum())\n","\n","print(\"\\nSummary Statistics:\")\n","print(df.describe())\n","\n","return df\n","\n","# 2. Handle Missing Data\n","def handle_missing_data(df, target_column):\n","    # Drop categorical columns except the target\n","    categorical_columns = df.select_dtypes(include=['object']).columns\n","    df = df.drop(columns=[col for col in categorical_columns if col != target_column])\n","\n","    # Check for missing values and handle them\n","    missing_info = df.isnull().sum() / len(df) * 100\n","    for column in df.columns:\n","        if missing_info[column] > 10:\n","            # Impute columns with >10% missing values with mean\n","            df[column].fillna(df[column].mean(), inplace=True)\n","        else:\n","            # Drop rows with missing values if <10% missing\n","            df.dropna(subset=[column], inplace=True)\n","    return df\n","\n","# 3. Feature Engineering\n","def split_features_target(df, target_column):\n","    X = df.drop(columns=[target_column]).values\n","    y = df[target_column].values\n","    return X, y\n","\n","def train_test_split(X, y, test_size=0.3, random_state=42):\n","    np.random.seed(random_state)\n","    indices = np.arange(len(X))\n","    np.random.shuffle(indices)\n","\n","    split_idx = int(len(X) * (1 - test_size))\n","    train_indices, test_indices = indices[:split_idx], indices[split_idx:]\n","\n","    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n","\n","# 4. Implement KNN\n","def euclidean_distance(point1, point2):\n","    return np.sqrt(np.sum((point1 - point2) ** 2))\n","\n","def knn_predict_single(X_train, y_train, query, k=3):\n","    # Compute distances from query to all training points\n","    distances = [euclidean_distance(query, x) for x in X_train]\n","\n","    # Get the indices of the k-nearest neighbors\n","    k_indices = np.argsort(distances)[:k]\n","\n","    # Get the labels of the k-nearest neighbors\n","    k_nearest_labels = [y_train[i] for i in k_indices]\n","\n","    # Determine the most common class label\n","    most_common = Counter(k_nearest_labels).most_common(1)\n","    return most_common[0][0]\n","\n","def knn_predict(X_train, y_train, X_test, k=3):\n","    predictions = [knn_predict_single(X_train, y_train, query, k) for query in X_test]\n","    return predictions\n","\n","def accuracy_score(y_true, y_pred):\n","    correct = sum(np.array(y_true) == np.array(y_pred))\n","    return correct / len(y_true)\n","\n","# Main Workflow\n","def main():\n","    # Load and explore dataset\n","    file_path = \"/content/drive/MyDrive/diabetes.csv\"\n","    target_column = \"Survived\"  # Replace with the actual target column name in your dataset\n","    df = load_and_explore_dataset(file_path)\n","\n","    # Handle missing data\n","    df_cleaned = handle_missing_data(df, target_column)\n","\n","    # Display cleaned data\n","    print(\"\\nData after processing:\")\n","    print(df_cleaned.head())\n","    print(\"\\nMissing values after processing:\")\n","    print(df_cleaned.isnull().sum())\n","\n","    # Feature engineering\n","    X, y = split_features_target(df_cleaned, target_column)\n","    X_train, X_test, y_train, y_test = train_test_split(X, y)\n","\n","    # Implement KNN\n","    k = 5  # Define the number of neighbors\n","    y_pred = knn_predict(X_train, y_train, X_test, k)\n","\n","    # Evaluate performance\n","    acc = accuracy_score(y_test, y_pred)\n","    print(f\"\\nAccuracy: {acc:.2f}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"id":"WF01HQohxG4W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gxP8pid0xy_d"},"execution_count":null,"outputs":[]}]}